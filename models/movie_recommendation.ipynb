{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aadb84bb-9ac3-4bcc-91de-c42847a8b597",
   "metadata": {},
   "source": [
    "# Movie Ratings Matrix Factorization (Collaborative Filtering)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922e83e9-d208-46ff-b955-934847f1ecb3",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fa89d59-cee9-48ff-a958-307bab0b4610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016ca127-97a9-4b9e-9693-e55447c865f9",
   "metadata": {},
   "source": [
    "## Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1f26ce-f197-4e4b-8c30-b5389cd06335",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/spark-3.2.1/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# Change the number of cores in this code block\n",
    "# by setting `spark.master` to `local[n]` where\n",
    "# n is the number of cores\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "conf = pyspark.SparkConf().setAll([('spark.master', 'local[4]'),\n",
    "                                   ('spark.app.name', 'MatrixFactorization'),\n",
    "                                   ('spark.memory.offHeap.enabled', True),\n",
    "                                   ('spark.memory.offHeap.size','4g'),\n",
    "                                   ('spark.executor.memory', '4g'), \n",
    "                                   ('spark.driver.memory','6g')])\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3ade65-8682-49d2-95cf-16b781ae5683",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.setLogLevel(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3abbb7b-826f-458c-9da6-2bf639e05e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878ab34c-05cc-4517-af5a-176880f60bcb",
   "metadata": {},
   "source": [
    "## Load final ratings files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acda688-d8e8-4b82-a1e5-b6480ab8a383",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = spark.read.csv(\"file:///home/work/data/ratings_100_max.csv\", inferSchema=True, header=True).repartition(100)\n",
    "ratings_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc5e86a-932d-48ac-b8e8-39b2e19f5e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test = ratings_df.randomSplit([0.8, 0.2], seed=0)\n",
    "train, test = ratings_df.randomSplit([0.5, 0.5], seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709a8de1-33a0-40c6-8dee-5ee0bcd02a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking number of partitions \n",
    "# train.rdd.getNumPartitions()\n",
    "ratings_df.unpersist()\n",
    "train.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e909bf6d-77d6-40cd-8f8c-6b8445a07b85",
   "metadata": {},
   "source": [
    "## Building ALS model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17447ea-5ccf-4968-90d8-9ac215587ced",
   "metadata": {},
   "source": [
    "### Alternating Least Squares (ALS) matrix factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf8117a-9fbd-442c-90a7-407c677e112e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternating Least Squares (ALS) matrix factorization\n",
    "from pyspark.ml.recommendation import ALS\n",
    "als = ALS(userCol='userId',\n",
    "          itemCol='movieId',\n",
    "          ratingCol='rating',\n",
    "          nonnegative=True, #setting this to true since we are using ratings > 0.\n",
    "          implicitPrefs=False, #setting this to false as we are using explicit ratings.\n",
    "          coldStartStrategy='drop', # to make sure we don't get NaN evaluation metrics\n",
    "          maxIter=15\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66be9f7-8e3f-4f3d-98cf-75c8b51994af",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9782f34-51a6-4443-8b2d-145c07f47bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "param_grid = ParamGridBuilder() \\\n",
    "                .addGrid(als.rank,[50, 75, 100, 125]) \\\n",
    "                .addGrid(als.regParam,[.1, .2, .3, .4]) \\\n",
    "                .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac7d835-47d7-4e7c-ad4d-05b39df08f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator = RegressionEvaluator(metricName='rmse',\n",
    "                                labelCol='rating',\n",
    "                                predictionCol='prediction')                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43266aa3-71a5-401a-b732-1a6084b47f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.ml.tuning import CrossValidator\n",
    "# cv = CrossValidator(estimator=als,\n",
    "#                     estimatorParamMaps=param_grid,\n",
    "#                     evaluator=evaluator,\n",
    "#                     numFolds=10)\n",
    "# cv.fit(test)\n",
    "from pyspark.ml.tuning import TrainValidationSplit\n",
    "tvs = TrainValidationSplit(estimator=als, estimatorParamMaps=param_grid, evaluator=evaluator, parallelism=2, seed=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411b45cd-6b0c-4963-ac2e-1db8effab750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6e78b4-d754-487a-af39-f73945c3de21",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tvs_model = tvs.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8658bb54-2207-4dc0-acc3-c3045a3a5eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"Test RMSE = \",evaluator.evaluate(best_model.transform(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e67e48d-e574-4cfb-a533-ef0e1eda4d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train RMSE = \",evaluator.evaluate(best_model.transform(train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9941626e-1199-4e20-8a8c-ad97a031be65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"file:///home/work/data/als_model_v2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee8a1bb-4163-445c-95bb-2b526aa1203c",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_files = True\n",
    "if write_files:\n",
    "    tvs_model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b15d3aa-440c-4d26-bb30-7127fc778b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import TrainValidationSplitModel\n",
    "tvsModelRead = TrainValidationSplitModel.read().load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81908983-42a0-43f1-a62c-e25e63e78112",
   "metadata": {},
   "outputs": [],
   "source": [
    "tvsModelRead.validationMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c16fdf-8d3e-46be-b90f-57fa4f457664",
   "metadata": {},
   "outputs": [],
   "source": [
    "tvsModelRead.explainParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb2df2a-711f-4cbd-895f-d4999eedb362",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tvsModelRead.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165e1cfb-395f-48ec-8996-adf115e7424e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Model Train RMSE = \",evaluator.evaluate(best_model.transform(train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9559ca36-7442-42c0-b405-1b3a7c6d9dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"Best Model Test RMSE = \",evaluator.evaluate(best_model.transform(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcfc77b-dbd8-45b6-844b-75afcb7fcc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = best_model.recommendForAllUsers(5)\n",
    "recommendations.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530f723a-f755-418d-bdbb-fa7a5df3e602",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_recommendations = recommendations.withColumn('recommendation', explode('recommendations')) \\\n",
    "                .select('userId',col('recommendation.movieId'),col('recommendation.rating'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7681d9-0ab1-4809-8e54-b42dda2f1ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recommendations\n",
    "top_5_recommendations.join(test.select('movieId','genres'), on='movieId') \\\n",
    "                    .filter('userId = 1') \\\n",
    "                    .sort('rating', ascending = False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0631bd0a-3114-46fe-a03c-95602fb540da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actual User Prefernces\n",
    "test.select('userId','movieId','genres') \\\n",
    "    .filter('userId = 1') \\\n",
    "    .sort('rating', ascending = False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741d87a7-56a9-4b1d-8348-c2e377d1a97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fbf645-bc3c-47e3-881b-13c635f26ae8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
